{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Integrate with Amazon Bedrock Knowledge Bases:\n",
    "After processed the audio and video files with a BDA project, next it is time to integrate with Bedrock KB.\n",
    "## Steps involved in this integration: \n",
    "- Set up a knowledge base to parse documents using Amazon Bedrock Data Automation as the parser.\n",
    "- Ingest the processed data into the knowledge base for retrieval and response generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Please run this notebook after you finish running the first notebook: 01_data_prep_using_bda.ipynb, the notebook cell one at a time instead of using \"Run All Cells\" option.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup notebook and boto3 clients\n",
    "\n",
    "In this step, we will import some necessary libraries that will be used throughout this notebook. To use Amazon Bedrock Data Automation (BDA) with boto3, you'll need to ensure you have the latest version of the AWS SDK for Python (boto3) installed. Version Boto3 1.35.96 of later is required.\n",
    "\n",
    "Note: At time of Public Preview launch, BDA is available in us-west-2 only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt --no-deps --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from datetime import datetime\n",
    "import time\n",
    "from time import sleep\n",
    "import pprint\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from IPython.display import JSON, IFrame, Audio, display, clear_output\n",
    "import IPython.display as display\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import base64\n",
    "\n",
    "# Get current path and go up two parent directories\n",
    "current_path = Path().resolve()\n",
    "parent_path = current_path.parent  # Go up two levels\n",
    "\n",
    "# Add to sys.path if not already there\n",
    "if str(parent_path) not in sys.path:\n",
    "    sys.path.append(str(parent_path))\n",
    "\n",
    "# Now you can import from utils\n",
    "from utils.knowledge_base import BedrockKnowledgeBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clients\n",
    "suffix = random.randrange(200, 900)\n",
    "\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "region_name = \"us-east-1\" # can be removed ones BDA is GA and available in other regions.\n",
    "region = region_name\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region_name)\n",
    "\n",
    "bda_client = boto3.client('bedrock-data-automation', region_name=region_name)\n",
    "bda_runtime_client = boto3.client('bedrock-data-automation-runtime', region_name=region_name)\n",
    "\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime') \n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'bedrock-bda-kb-845-885964308737-1' does not exist. Creating it now...\n",
      "Bucket 'bedrock-bda-kb-845-885964308737-1' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Copy local BDA output files to a S3 bucket for KB integration\n",
    "# Function to check if the bucket exists, if not, create the data_bucket\n",
    "from utils.knowledge_base_operators import bucket_exists\n",
    "suffix = random.randrange(200, 900)\n",
    "bucket_name_kb = f'bedrock-bda-kb-{suffix}-{account_id}-1'            \n",
    "# Create S3 bucket for the KB if it doesn't exist\n",
    "if not bucket_exists(bucket_name_kb):\n",
    "    print(f\"Bucket '{bucket_name_kb}' does not exist. Creating it now...\")\n",
    "    if region == \"us-east-1\":\n",
    "        s3_client.create_bucket(Bucket=bucket_name_kb)\n",
    "    else:\n",
    "        s3_client.create_bucket(\n",
    "            Bucket=bucket_name_kb,\n",
    "            CreateBucketConfiguration={'LocationConstraint': region}\n",
    "        )\n",
    "    print(f\"Bucket '{bucket_name_kb}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Bucket '{bucket_name_kb}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading PDF from https://s2.q4cdn.com/299287126/files/doc_financials/2024/q4/Webslides_Q424_Final.pdf\n",
      "Converting PDF to images\n",
      "Uploading images to S3\n",
      "{'status': 'success', 'pdf_name': 'Webslides_Q424_Final.pdf', 'uploaded_files': ['bda/dataset/pdf_images/Webslides_Q424_Final/page_1.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_2.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_3.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_4.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_5.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_6.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_7.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_8.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_9.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_10.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_11.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_12.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_13.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_14.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_15.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_16.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_17.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_18.png', 'bda/dataset/pdf_images/Webslides_Q424_Final/page_19.png'], 'total_pages': 19}\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_1.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_2.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_3.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_4.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_5.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_6.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_7.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_8.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_9.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_10.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_11.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_12.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_13.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_14.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_15.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_16.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_17.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_18.png\n",
      "Verified: s3://bedrock-bda-kb-845-885964308737-1/bda/dataset/pdf_images/Webslides_Q424_Final/page_19.png\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import fitz\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import boto3\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "\n",
    "# Create the static directory if it doesn't exist\n",
    "os.makedirs('static', exist_ok=True)\n",
    "\n",
    "\n",
    "def download_pdf_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        return io.BytesIO(response.content)\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to download PDF from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def pdf_to_images(pdf_content, quality=75, max_size=(1024, 1024)):\n",
    "    \"\"\"Convert PDF to list of images\"\"\"\n",
    "    images = []\n",
    "    try:\n",
    "        with fitz.open(stream=pdf_content.getvalue(), filetype=\"pdf\") as doc:\n",
    "            for page_num, page in enumerate(doc):\n",
    "                # Get page pixmap\n",
    "                pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72))\n",
    "                # Convert to PIL Image\n",
    "                image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "                \n",
    "                # Resize if needed\n",
    "                if image.size[0] > max_size[0] or image.size[1] > max_size[1]:\n",
    "                    image.thumbnail(max_size, Image.Resampling.LANCZOS)\n",
    "                \n",
    "                # Convert to bytes\n",
    "                img_byte_arr = io.BytesIO()\n",
    "                image.save(img_byte_arr, format='PNG', optimize=True, quality=quality)\n",
    "                img_byte_arr.seek(0)\n",
    "                \n",
    "                images.append({\n",
    "                    'page_num': page_num + 1,\n",
    "                    'image_data': img_byte_arr\n",
    "                })\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting PDF to images: {e}\")\n",
    "        return None\n",
    "\n",
    "def upload_images_to_s3(images, bucket_name, s3_prefix, pdf_name):\n",
    "    \"\"\"Upload images to S3\"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    uploaded_files = []\n",
    "    \n",
    "    try:\n",
    "        for img in images:\n",
    "            # Create filename for the image\n",
    "            base_name = os.path.splitext(pdf_name)[0]\n",
    "            image_key = f\"{s3_prefix}/{base_name}/page_{img['page_num']}.png\"\n",
    "            \n",
    "            # Upload to S3\n",
    "            s3_client.upload_fileobj(\n",
    "                img['image_data'],\n",
    "                bucket_name,\n",
    "                image_key\n",
    "            )\n",
    "            \n",
    "            uploaded_files.append(image_key)\n",
    "            \n",
    "        return uploaded_files\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading to S3: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_pdf_to_images_s3(pdf_url, bucket_name, s3_prefix):\n",
    "    \"\"\"Main function to process PDF to images and upload to S3\"\"\"\n",
    "    try:\n",
    "        # Download PDF\n",
    "        print(f\"Downloading PDF from {pdf_url}\")\n",
    "        pdf_content = download_pdf_from_url(pdf_url)\n",
    "        if not pdf_content:\n",
    "            return {\"error\": \"Failed to download PDF\"}\n",
    "        \n",
    "        # Get PDF filename from URL\n",
    "        pdf_name = os.path.basename(urlparse(pdf_url).path)\n",
    "        \n",
    "        # Convert to images\n",
    "        print(\"Converting PDF to images\")\n",
    "        images = pdf_to_images(pdf_content)\n",
    "        if not images:\n",
    "            return {\"error\": \"Failed to convert PDF to images\"}\n",
    "        \n",
    "        # Upload to S3\n",
    "        print(\"Uploading images to S3\")\n",
    "        uploaded_files = upload_images_to_s3(images, bucket_name, s3_prefix, pdf_name)\n",
    "        if not uploaded_files:\n",
    "            return {\"error\": \"Failed to upload images to S3\"}\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"pdf_name\": pdf_name,\n",
    "            \"uploaded_files\": uploaded_files,\n",
    "            \"total_pages\": len(images)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Usage\n",
    "pdf_url = \"https://s2.q4cdn.com/299287126/files/doc_financials/2024/q4/Webslides_Q424_Final.pdf\"\n",
    "bucket_name = bucket_name_kb  # Your bucket name\n",
    "s3_prefix = \"bda/dataset/pdf_images\"  # Prefix for the images in S3\n",
    "\n",
    "# Process PDF and upload images\n",
    "result = process_pdf_to_images_s3(pdf_url, bucket_name, s3_prefix)\n",
    "print(result)\n",
    "\n",
    "# Verify uploads if successful\n",
    "if result.get(\"status\") == \"success\":\n",
    "    s3_client = boto3.client('s3')\n",
    "    for s3_key in result[\"uploaded_files\"]:\n",
    "        try:\n",
    "            s3_client.head_object(Bucket=bucket_name, Key=s3_key)\n",
    "            print(f\"Verified: s3://{bucket_name}/{s3_key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to verify {s3_key}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current timestamp\n",
    "current_time = time.time()\n",
    "\n",
    "# Format the timestamp as a string\n",
    "timestamp_str = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(current_time))[-7:]\n",
    "# Create the suffix using the timestamp\n",
    "suffix = f\"{timestamp_str}\"\n",
    "\n",
    "knowledge_base_name = f\"bedrock-multi-modal-kb-{suffix}\"\n",
    "knowledge_base_description = \"Multi-modal RAG knowledge base.\"\n",
    "\n",
    "#foundation_model = \"anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Knowledge Base creation \n",
    "\n",
    "In this notebook, the process of creating a KB is simplified by using a wrapper function from the knowledge_base.py file in \"utils\" folder of this notebook. The whole process of creating data source, creating a KB, creating an embedding index, saving the index in a vector data store is simplified by using this function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please uncomment the data sources that you want to add and update the placeholder values accordingly.\n",
    "\n",
    "#data=[{\"type\": \"S3\", \"bucket_name\": bucket_name, \"inclusionPrefixes\": [\"bda/dataset/\"]}]\n",
    "data=[{\"type\": \"S3\", \"bucket_name\": bucket_name_kb}]\n",
    "\n",
    "\n",
    "                # {\"type\": \"SHAREPOINT\", \"tenantId\": \"888d0b57-69f1-4fb8-957f-e1f0bedf64de\", \"domain\": \"yourdomain\",\n",
    "                #   \"authType\": \"OAUTH2_CLIENT_CREDENTIALS\",\n",
    "                #  \"credentialsSecretArn\": f\"arn:aws::secretsmanager:{region_name}:secret:<<your_secret_name>>\",\n",
    "                #  \"siteUrls\": [\"https://yourdomain.sharepoint.com/sites/mysite\"]\n",
    "                # },\n",
    "    \n",
    "                \n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Create Knowledge Base with Multi modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-12 06:49:26,515] p12991 {credentials.py:1136} INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "[2025-08-12 06:49:26,685] p12991 {credentials.py:1136} INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================\n",
      "Step 1 - Creating or retrieving S3 bucket(s) for Knowledge Base documents\n",
      "['bedrock-bda-kb-845-885964308737-1', 'bedrock-multi-modal-kb-2064921-intermediate-2064921-f']\n",
      "buckets_to_check:  ['bedrock-bda-kb-845-885964308737-1', 'bedrock-multi-modal-kb-2064921-intermediate-2064921-f']\n",
      "Bucket bedrock-bda-kb-845-885964308737-1 already exists - retrieving it!\n",
      "Creating bucket bedrock-multi-modal-kb-2064921-intermediate-2064921-f\n",
      "========================================================================================\n",
      "Step 2 - Creating Knowledge Base Execution Role (AmazonBedrockExecutionRoleForKnowledgeBase_2064921-f) and Policies\n",
      "========================================================================================\n",
      "Step 3 - Creating OSS encryption, network and data access policies\n",
      "========================================================================================\n",
      "Step 4 - Creating OSS Collection (this step takes a couple of minutes to complete)\n",
      "{ 'ResponseMetadata': { 'HTTPHeaders': { 'connection': 'keep-alive',\n",
      "                                         'content-length': '320',\n",
      "                                         'content-type': 'application/x-amz-json-1.0',\n",
      "                                         'date': 'Tue, 12 Aug 2025 06:49:28 '\n",
      "                                                 'GMT',\n",
      "                                         'x-amzn-requestid': 'bf61d312-93a6-4742-a896-4c4046500222'},\n",
      "                        'HTTPStatusCode': 200,\n",
      "                        'RequestId': 'bf61d312-93a6-4742-a896-4c4046500222',\n",
      "                        'RetryAttempts': 0},\n",
      "  'createCollectionDetail': { 'arn': 'arn:aws:aoss:us-east-1:885964308737:collection/n9uuz90z5qj5mw7zstd7',\n",
      "                              'createdDate': 1754981368135,\n",
      "                              'id': 'n9uuz90z5qj5mw7zstd7',\n",
      "                              'kmsKeyArn': 'auto',\n",
      "                              'lastModifiedDate': 1754981368135,\n",
      "                              'name': 'bedrock-sample-rag-2064921-f',\n",
      "                              'standbyReplicas': 'ENABLED',\n",
      "                              'status': 'CREATING',\n",
      "                              'type': 'VECTORSEARCH'}}\n",
      "n9uuz90z5qj5mw7zstd7.us-east-1.aoss.amazonaws.com\n",
      "Creating collection...\n",
      "..............................\n",
      "Collection successfully created:\n",
      "[ { 'arn': 'arn:aws:aoss:us-east-1:885964308737:collection/n9uuz90z5qj5mw7zstd7',\n",
      "    'collectionEndpoint': 'https://n9uuz90z5qj5mw7zstd7.us-east-1.aoss.amazonaws.com',\n",
      "    'createdDate': 1754981368135,\n",
      "    'dashboardEndpoint': 'https://n9uuz90z5qj5mw7zstd7.us-east-1.aoss.amazonaws.com/_dashboards',\n",
      "    'id': 'n9uuz90z5qj5mw7zstd7',\n",
      "    'kmsKeyArn': 'auto',\n",
      "    'lastModifiedDate': 1754981391210,\n",
      "    'name': 'bedrock-sample-rag-2064921-f',\n",
      "    'standbyReplicas': 'ENABLED',\n",
      "    'status': 'ACTIVE',\n",
      "    'type': 'VECTORSEARCH'}]\n",
      "Opensearch serverless arn:  arn:aws:iam::885964308737:policy/AmazonBedrockOSSPolicyForKnowledgeBase_2064921-f\n",
      "Sleeping for a minute to ensure data access rules have been enforced\n",
      "========================================================================================\n",
      "Step 5 - Creating OSS Vector Index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-12 06:50:59,022] p12991 {base.py:258} INFO - PUT https://n9uuz90z5qj5mw7zstd7.us-east-1.aoss.amazonaws.com:443/bedrock-sample-rag-index-2064921-f [status:200 request:0.441s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating index:\n",
      "{ 'acknowledged': True,\n",
      "  'index': 'bedrock-sample-rag-index-2064921-f',\n",
      "  'shards_acknowledged': True}\n",
      "========================================================================================\n",
      "Step 6 - Will create Lambda Function if chunking strategy selected as CUSTOM\n",
      "Not creating lambda function as chunking strategy is FIXED_SIZE\n",
      "========================================================================================\n",
      "Step 7 - Creating Knowledge Base\n",
      "{ 'createdAt': datetime.datetime(2025, 8, 12, 6, 51, 59, 219181, tzinfo=tzlocal()),\n",
      "  'description': 'Multi-modal RAG knowledge base.',\n",
      "  'knowledgeBaseArn': 'arn:aws:bedrock:us-east-1:885964308737:knowledge-base/PLSMJ4XIZT',\n",
      "  'knowledgeBaseConfiguration': { 'type': 'VECTOR',\n",
      "                                  'vectorKnowledgeBaseConfiguration': { 'embeddingModelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0',\n",
      "                                                                        'supplementalDataStorageConfiguration': { 'storageLocations': [ { 's3Location': { 'uri': 's3://bedrock-multi-modal-kb-2064921-intermediate-2064921-f'},\n",
      "                                                                                                                                          'type': 'S3'}]}}},\n",
      "  'knowledgeBaseId': 'PLSMJ4XIZT',\n",
      "  'name': 'bedrock-multi-modal-kb-2064921',\n",
      "  'roleArn': 'arn:aws:iam::885964308737:role/AmazonBedrockExecutionRoleForKnowledgeBase_2064921-f',\n",
      "  'status': 'CREATING',\n",
      "  'storageConfiguration': { 'opensearchServerlessConfiguration': { 'collectionArn': 'arn:aws:aoss:us-east-1:885964308737:collection/n9uuz90z5qj5mw7zstd7',\n",
      "                                                                   'fieldMapping': { 'metadataField': 'text-metadata',\n",
      "                                                                                     'textField': 'text',\n",
      "                                                                                     'vectorField': 'vector'},\n",
      "                                                                   'vectorIndexName': 'bedrock-sample-rag-index-2064921-f'},\n",
      "                            'type': 'OPENSEARCH_SERVERLESS'},\n",
      "  'updatedAt': datetime.datetime(2025, 8, 12, 6, 51, 59, 219181, tzinfo=tzlocal())}\n",
      "Creating Data Sources\n",
      "{ 'createdAt': datetime.datetime(2025, 8, 12, 6, 51, 59, 219181, tzinfo=tzlocal()),\n",
      "  'description': 'Multi-modal RAG knowledge base.',\n",
      "  'knowledgeBaseArn': 'arn:aws:bedrock:us-east-1:885964308737:knowledge-base/PLSMJ4XIZT',\n",
      "  'knowledgeBaseConfiguration': { 'type': 'VECTOR',\n",
      "                                  'vectorKnowledgeBaseConfiguration': { 'embeddingModelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0',\n",
      "                                                                        'supplementalDataStorageConfiguration': { 'storageLocations': [ { 's3Location': { 'uri': 's3://bedrock-multi-modal-kb-2064921-intermediate-2064921-f'},\n",
      "                                                                                                                                          'type': 'S3'}]}}},\n",
      "  'knowledgeBaseId': 'PLSMJ4XIZT',\n",
      "  'name': 'bedrock-multi-modal-kb-2064921',\n",
      "  'roleArn': 'arn:aws:iam::885964308737:role/AmazonBedrockExecutionRoleForKnowledgeBase_2064921-f',\n",
      "  'status': 'ACTIVE',\n",
      "  'storageConfiguration': { 'opensearchServerlessConfiguration': { 'collectionArn': 'arn:aws:aoss:us-east-1:885964308737:collection/n9uuz90z5qj5mw7zstd7',\n",
      "                                                                   'fieldMapping': { 'metadataField': 'text-metadata',\n",
      "                                                                                     'textField': 'text',\n",
      "                                                                                     'vectorField': 'vector'},\n",
      "                                                                   'vectorIndexName': 'bedrock-sample-rag-index-2064921-f'},\n",
      "                            'type': 'OPENSEARCH_SERVERLESS'},\n",
      "  'updatedAt': datetime.datetime(2025, 8, 12, 6, 51, 59, 219181, tzinfo=tzlocal())}\n",
      "Creating Data Sources\n",
      "1 data source: S3\n",
      "============Chunking config========\n",
      " {'chunkingConfiguration': {'chunkingStrategy': 'FIXED_SIZE', 'fixedSizeChunkingConfiguration': {'maxTokens': 300, 'overlapPercentage': 20}}}\n",
      "{ 'createdAt': datetime.datetime(2025, 8, 12, 6, 52, 2, 45094, tzinfo=tzlocal()),\n",
      "  'dataDeletionPolicy': 'DELETE',\n",
      "  'dataSourceConfiguration': { 's3Configuration': { 'bucketArn': 'arn:aws:s3:::bedrock-bda-kb-845-885964308737-1'},\n",
      "                               'type': 'S3'},\n",
      "  'dataSourceId': 'J80RGDUY4L',\n",
      "  'description': 'Multi-modal RAG knowledge base.',\n",
      "  'knowledgeBaseId': 'PLSMJ4XIZT',\n",
      "  'name': 'PLSMJ4XIZT-s3',\n",
      "  'status': 'AVAILABLE',\n",
      "  'updatedAt': datetime.datetime(2025, 8, 12, 6, 52, 2, 45094, tzinfo=tzlocal()),\n",
      "  'vectorIngestionConfiguration': { 'chunkingConfiguration': { 'chunkingStrategy': 'FIXED_SIZE',\n",
      "                                                               'fixedSizeChunkingConfiguration': { 'maxTokens': 300,\n",
      "                                                                                                   'overlapPercentage': 20}},\n",
      "                                    'parsingConfiguration': { 'bedrockDataAutomationConfiguration': { 'parsingModality': 'MULTIMODAL'},\n",
      "                                                              'parsingStrategy': 'BEDROCK_DATA_AUTOMATION'}}}\n",
      "[ { 'createdAt': datetime.datetime(2025, 8, 12, 6, 52, 2, 45094, tzinfo=tzlocal()),\n",
      "    'dataDeletionPolicy': 'DELETE',\n",
      "    'dataSourceConfiguration': { 's3Configuration': { 'bucketArn': 'arn:aws:s3:::bedrock-bda-kb-845-885964308737-1'},\n",
      "                                 'type': 'S3'},\n",
      "    'dataSourceId': 'J80RGDUY4L',\n",
      "    'description': 'Multi-modal RAG knowledge base.',\n",
      "    'knowledgeBaseId': 'PLSMJ4XIZT',\n",
      "    'name': 'PLSMJ4XIZT-s3',\n",
      "    'status': 'AVAILABLE',\n",
      "    'updatedAt': datetime.datetime(2025, 8, 12, 6, 52, 2, 45094, tzinfo=tzlocal()),\n",
      "    'vectorIngestionConfiguration': { 'chunkingConfiguration': { 'chunkingStrategy': 'FIXED_SIZE',\n",
      "                                                                 'fixedSizeChunkingConfiguration': { 'maxTokens': 300,\n",
      "                                                                                                     'overlapPercentage': 20}},\n",
      "                                      'parsingConfiguration': { 'bedrockDataAutomationConfiguration': { 'parsingModality': 'MULTIMODAL'},\n",
      "                                                                'parsingStrategy': 'BEDROCK_DATA_AUTOMATION'}}}]\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# For multi-modal RAG While instantiating BedrockKnowledgeBase, pass multi_modal= True and choose the parser you want to use\n",
    "\n",
    "knowledge_base = BedrockKnowledgeBase(\n",
    "    kb_name=f'{knowledge_base_name}',\n",
    "    kb_description=knowledge_base_description,\n",
    "    data_sources=data,\n",
    "    multi_modal= True,\n",
    "    parser= 'BEDROCK_DATA_AUTOMATION', #'BEDROCK_Data Automation service is used'\n",
    "    chunking_strategy = \"FIXED_SIZE\", \n",
    "    suffix = f'{suffix}-f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Start data ingestion job to KB\n",
    "\n",
    "Once the KB and data source(s) created, we can start the ingestion job for each data source. During the ingestion job, KB will fetch the documents from the data source, Parse the document to extract text, chunk it based on the chunking size provided, create embeddings of each chunk and then write it to the vector database, in this case OSS.\n",
    "\n",
    "NOTE: Currently, you can only kick-off one ingestion job at one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job 1 started successfully\n",
      "\n",
      "{ 'dataSourceId': 'J80RGDUY4L',\n",
      "  'ingestionJobId': 'G0BZM7GQAQ',\n",
      "  'knowledgeBaseId': 'PLSMJ4XIZT',\n",
      "  'startedAt': datetime.datetime(2025, 8, 12, 6, 52, 44, 279427, tzinfo=tzlocal()),\n",
      "  'statistics': { 'numberOfDocumentsDeleted': 0,\n",
      "                  'numberOfDocumentsFailed': 0,\n",
      "                  'numberOfDocumentsScanned': 19,\n",
      "                  'numberOfMetadataDocumentsModified': 0,\n",
      "                  'numberOfMetadataDocumentsScanned': 0,\n",
      "                  'numberOfModifiedDocumentsIndexed': 0,\n",
      "                  'numberOfNewDocumentsIndexed': 19},\n",
      "  'status': 'COMPLETE',\n",
      "  'updatedAt': datetime.datetime(2025, 8, 12, 6, 55, 10, 75255, tzinfo=tzlocal())}\n",
      "........................................"
     ]
    }
   ],
   "source": [
    "# ensure that the kb is available\n",
    "time.sleep(30)\n",
    "# sync knowledge base\n",
    "knowledge_base.start_ingestion_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'PLSMJ4XIZT'\n",
      "Stored 'kb_id' (str)\n"
     ]
    }
   ],
   "source": [
    "# keep the kb_id for invocation later in the invoke request\n",
    "kb_id = knowledge_base.get_knowledge_base_id()\n",
    "%store kb_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 -  Test the Knowledge Base\n",
    "Now the Knowlegde Base is available we can test it out using the [**retrieve**](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-agent-runtime/client/retrieve.html) and [**retrieve_and_generate**](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-agent-runtime/client/retrieve_and_generate.html) functions. \n",
    "\n",
    "#### Testing Knowledge Base with Retrieve and Generate API\n",
    "\n",
    "Let's first test the knowledge base using the retrieve and generate API. With this API, Bedrock takes care of retrieving the necessary references from the knowledge base and generating the final answer using a foundation model from Bedrock.\n",
    "\n",
    "query = Give me the summary of the AWS Rethink podcast hosted by Nolan Chen and Malini Chatterjee?\n",
    "\n",
    "The right response for this query is expected to fetch from a the audio transcript ingested in Knowledge Bases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Show me figures of Amazon TTM operation income and net sales\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the retrieved results, the TTM operation income of Amazon is $68.6B, and the TTM net sales is $637.0B.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# foundation_model = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "foundation_model = \"amazon.nova-pro-v1:0\"\n",
    "\n",
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": query\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            \"modelArn\": \"arn:aws:bedrock:{}::foundation-model/{}\".format(region, foundation_model),\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\":5\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response['output']['text'],end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying citation image:\n",
      "Error displaying image: '_NoValueType' object cannot be interpreted as an integer\n",
      "Displaying citation image:\n",
      "Error displaying image: '_NoValueType' object cannot be interpreted as an integer\n",
      "Displaying citation image:\n",
      "Error displaying image: '_NoValueType' object cannot be interpreted as an integer\n",
      "Error in callback <function _draw_all_if_interactive at 0x7fd3a0c6ab90> (for post_execute), with arguments args (),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "no implementation found for 'numpy.dot' on types that implement __array_function__: [<class 'numpy.ndarray'>, <class 'numpy.ndarray'>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/matplotlib/pyplot.py:279\u001b[0m, in \u001b[0;36m_draw_all_if_interactive\u001b[0;34m()\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_draw_all_if_interactive\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m matplotlib\u001b[38;5;241m.\u001b[39mis_interactive():\n\u001b[0;32m--> 279\u001b[0m         \u001b[43mdraw_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/matplotlib/_pylab_helpers.py:131\u001b[0m, in \u001b[0;36mGcf.draw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force \u001b[38;5;129;01mor\u001b[39;00m manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mstale:\n\u001b[0;32m--> 131\u001b[0m         \u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/matplotlib/backend_bases.py:1891\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_idle_drawing:\n\u001b[1;32m   1890\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_idle_draw_cntx():\n\u001b[0;32m-> 1891\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:382\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[1;32m    381\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/matplotlib/artist.py:94\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 94\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     96\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/matplotlib/artist.py:71\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/matplotlib/figure.py:3256\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3253\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   3254\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m-> 3256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3257\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[1;32m   3258\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[1;32m   3260\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/matplotlib/artist.py:71\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/matplotlib/patches.py:641\u001b[0m, in \u001b[0;36mPatch.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    639\u001b[0m transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\n\u001b[1;32m    640\u001b[0m tpath \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform_path_non_affine(path)\n\u001b[0;32m--> 641\u001b[0m affine \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_draw_paths_with_artist_properties(\n\u001b[1;32m    643\u001b[0m     renderer,\n\u001b[1;32m    644\u001b[0m     [(tpath, affine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    647\u001b[0m       \u001b[38;5;66;03m# transparent, but do if it is None.\u001b[39;00m\n\u001b[1;32m    648\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_facecolor \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_facecolor[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)])\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/matplotlib/transforms.py:2437\u001b[0m, in \u001b[0;36mCompositeGenericTransform.get_affine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b\u001b[38;5;241m.\u001b[39mget_affine()\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Affine2D(np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b\u001b[38;5;241m.\u001b[39mget_affine()\u001b[38;5;241m.\u001b[39mget_matrix(),\n\u001b[0;32m-> 2437\u001b[0m                            \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_a\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_matrix()))\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/matplotlib/transforms.py:2436\u001b[0m, in \u001b[0;36mCompositeGenericTransform.get_affine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b\u001b[38;5;241m.\u001b[39mget_affine()\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Affine2D(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2437\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_a\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: no implementation found for 'numpy.dot' on types that implement __array_function__: [<class 'numpy.ndarray'>, <class 'numpy.ndarray'>]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_base64_image(base64_string, figsize=(15, 15)):\n",
    "    try:\n",
    "        # Remove the data:image/png;base64, prefix if present\n",
    "        if 'data:image/png;base64,' in base64_string:\n",
    "            base64_string = base64_string.split('base64,')[1]\n",
    "            \n",
    "        # Decode base64 string\n",
    "        image_data = base64.b64decode(base64_string)\n",
    "        \n",
    "        # Convert to PIL Image\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "        \n",
    "        # Display the image\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error displaying image: {str(e)}\")\n",
    "\n",
    "# Extract and display the image from citations\n",
    "citations = response['citations'][0]\n",
    "if 'retrievedReferences' in citations:\n",
    "    for ref in citations['retrievedReferences']:\n",
    "        if 'content' in ref and 'byteContent' in ref['content']:\n",
    "            base64_image = ref['content']['byteContent']\n",
    "            print(\"Displaying citation image:\")\n",
    "            display_base64_image(base64_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "Please make sure to uncomment and run the below section to delete all the resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================Deleting Knowledge Base and associated resources==============================\n",
      "\n",
      "Deleted data source 17K3JQ27XZ\n",
      "======== Knowledge base and all data sources deleted =========\n",
      "Found bucket bedrock-bda-kb-319-885964308737-1\n",
      "Deleted all objects in bucket bedrock-bda-kb-319-885964308737-1\n",
      "Deleted bucket bedrock-bda-kb-319-885964308737-1\n",
      "Found bucket bedrock-multi-modal-kb-2005932-intermediate-2005932-f\n",
      "Deleted all objects in bucket bedrock-multi-modal-kb-2005932-intermediate-2005932-f\n",
      "Deleted bucket bedrock-multi-modal-kb-2005932-intermediate-2005932-f\n",
      "======== S3 bucket deletion process completed =========\n",
      "Found role AmazonBedrockExecutionRoleForKnowledgeBase_2005932-f\n",
      "======Attached policies with role AmazonBedrockExecutionRoleForKnowledgeBase_2005932-f========\n",
      " [{'PolicyName': 'AmazonBedrockBDAPolicyForKnowledgeBase_2005932-f', 'PolicyArn': 'arn:aws:iam::885964308737:policy/AmazonBedrockBDAPolicyForKnowledgeBase_2005932-f'}, {'PolicyName': 'AmazonBedrockOSSPolicyForKnowledgeBase_2005932-f', 'PolicyArn': 'arn:aws:iam::885964308737:policy/AmazonBedrockOSSPolicyForKnowledgeBase_2005932-f'}, {'PolicyName': 'AmazonBedrockFoundationModelPolicyForKnowledgeBase_2005932-f', 'PolicyArn': 'arn:aws:iam::885964308737:policy/AmazonBedrockFoundationModelPolicyForKnowledgeBase_2005932-f'}, {'PolicyName': 'AmazonBedrockS3PolicyForKnowledgeBase_2005932-f', 'PolicyArn': 'arn:aws:iam::885964308737:policy/AmazonBedrockS3PolicyForKnowledgeBase_2005932-f'}, {'PolicyName': 'AmazonBedrockCloudWatchPolicyForKnowledgeBase_2005932-f', 'PolicyArn': 'arn:aws:iam::885964308737:policy/AmazonBedrockCloudWatchPolicyForKnowledgeBase_2005932-f'}]\n",
      "Detached policy AmazonBedrockBDAPolicyForKnowledgeBase_2005932-f from role AmazonBedrockExecutionRoleForKnowledgeBase_2005932-f\n",
      "Deleted policy AmazonBedrockBDAPolicyForKnowledgeBase_2005932-f from role AmazonBedrockExecutionRoleForKnowledgeBase_2005932-f\n",
      "Detached policy AmazonBedrockOSSPolicyForKnowledgeBase_2005932-f from role AmazonBedrockExecutionRoleForKnowledgeBase_2005932-f\n",
      "Deleted policy AmazonBedrockOSSPolicyForKnowledgeBase_2005932-f from role AmazonBedrockExecutionRoleForKnowledgeBase_2005932-f\n",
      "Detached policy AmazonBedrockFoundationModelPolicyForKnowledgeBase_2005932-f from role AmazonBedrockExecutionRoleForKnowledgeBase_2005932-f\n",
      "Deleted policy AmazonBedrockFoundationModelPolicyForKnowledgeBase_2005932-f from role AmazonBedrockExecutionRoleForKnowledgeBase_2005932-f\n",
      "Detached policy AmazonBedrockS3PolicyForKnowledgeBase_2005932-f from role AmazonBedrockExecutionRoleForKnowledgeBase_2005932-f\n",
      "Deleted policy AmazonBedrockS3PolicyForKnowledgeBase_2005932-f from role AmazonBedrockExecutionRoleForKnowledgeBase_2005932-f\n",
      "Detached policy AmazonBedrockCloudWatchPolicyForKnowledgeBase_2005932-f from role AmazonBedrockExecutionRoleForKnowledgeBase_2005932-f\n",
      "Deleted policy AmazonBedrockCloudWatchPolicyForKnowledgeBase_2005932-f from role AmazonBedrockExecutionRoleForKnowledgeBase_2005932-f\n",
      "Deleted role AmazonBedrockExecutionRoleForKnowledgeBase_2005932-f\n",
      "======== All IAM roles and policies deleted =========\n",
      "======== Vector Index, collection and associated policies deleted =========\n"
     ]
    }
   ],
   "source": [
    "# delete role and policies\n",
    "print(\"===============================Deleting Knowledge Base and associated resources==============================\\n\")\n",
    "knowledge_base.delete_kb(delete_s3_bucket=True, delete_iam_roles_and_policies=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "By following this guide, you can effectively harness the power of Amazon Bedrocks features to build a robust Multimodal RAG application tailored to your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
